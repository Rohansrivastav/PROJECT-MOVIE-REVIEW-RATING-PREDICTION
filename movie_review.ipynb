{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#CLEANING THE REVIEWS USING NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem.porter import PorterStemmer \n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\91763\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer=RegexpTokenizer('[a-zA-Z]+')\n",
    "stopwords=set(stopwords.words('english'))\n",
    "ps=PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "important_words=[\"not\",\"don't\",\"doesn't\",\"didn'\",\"didn't\",\"doesn'\",\"doesn't\",\"don\",\"dont't\",\"wasn\",\"wasn't\"]\n",
    "stopwords=[i for i in stopwords if i not in important_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaned_reviews(review):\n",
    "    review=review.lower()\n",
    "    review=review.replace(\"<br /><br />\",\" \")\n",
    "    #tokenize\n",
    "    tokens=tokenizer.tokenize(review)\n",
    "    new_tokens=[token for token in tokens if token not in stopwords]\n",
    "    stemmed_tokens=[ps.stem(token)for token in new_tokens]\n",
    "    cleaned_review=' '.join(stemmed_tokens)\n",
    "    return cleaned_review\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#NOW WE WILL WRITE A FUNCTION THAT WILL ACCEPT A INPUT FILE AND RETURNS A CLEANED DOCUMENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaned_document(inputfile,outputfile):\n",
    "    out=open(outputfile,'w',encoding=\"utf8\")\n",
    "    with open(inputfile,encoding=\"utf8\")as f:\n",
    "        reviews=f.readlines()\n",
    "    for review in reviews:\n",
    "        cleaned_review=cleaned_reviews(review)\n",
    "        print(cleaned_review,file=out)\n",
    "    out.close()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#CLEANING THE TRAINING DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_document('imdb_trainX.txt','cleaned_input_reviews')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#CLEANING THE TESTING DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_document('imdb_testX.txt','cleaned_output_reviews')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#VECTORIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv=CountVectorizer(ngram_range=(1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_rev=[]\n",
    "with open('cleaned_input_reviews','r',encoding=\"utf8\") as f:\n",
    "    cleaned_rev=f.readlines()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cleaned_rev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(cleaned_rev)):\n",
    "    cleaned_rev[i]=cleaned_rev[i][:-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vec=cv.fit_transform(cleaned_rev[:500]).toarray()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 65143)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_vec.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#VECTORIZATION ON TESTING DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtest_=[]\n",
    "with open('cleaned_output_reviews','r',encoding=\"utf8\") as f:\n",
    "    xtest_=f.readlines()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 65143)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_vec=cv.transform(xtest_[:500]).toarray()\n",
    "test_vec.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#USING MULTINOMIAL NAIVE BAYES "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings=[]\n",
    "with open('imdb_trainY.txt','r',encoding=\"utf8\") as f:\n",
    "    ratings=f.readlines()\n",
    "    for i in range (500):\n",
    "        ratings[i]=int(ratings[i][:2])    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings=ratings[:500]\n",
    "len(ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB,GaussianNB,BernoulliNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnb=MultinomialNB()\n",
    "model=mnb.fit(train_vec,ratings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#training accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100.0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(train_vec,ratings)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions=model.predict(test_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_ratings=[]\n",
    "with open('imdb_testY.txt','r',encoding=\"utf8\") as f:\n",
    "    output_ratings=f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_ratings=output_ratings[:500]\n",
    "for i in range (500):\n",
    "        output_ratings[i]=int(output_ratings[i][:2]) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "predictions=np.array(predictions)\n",
    "output_ratings=np.array(output_ratings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#CALCULATING TESTING ACCURACY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42.6\n"
     ]
    }
   ],
   "source": [
    "num=np.sum(predictions==output_ratings)\n",
    "accuracy=num/len(predictions)\n",
    "print(accuracy*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#LETS TRY TFIDFVECTORIZER FOR VECTORIZATION WHICH ASSIGN WEIGHTS TO EACH OF THE VECTORS , THE IDEA BEHIND THIS ALGO IS THAT THE WORD WHICH IS APPEARING IN MOST OF THE DOCUMENTS SHOULD HAVE A LESS WEIGHT AS IT IS GIVING US THE LEAST INFORMATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf=TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#vectorizing the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 9178)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_vec_2=tfidf.fit_transform(cleaned_rev[:500]).toarray()\n",
    "train_vec_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 9178)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#vectorizing the testing data\n",
    "\n",
    "test_vec_2=tfidf.transform(xtest_[:500]).toarray()\n",
    "test_vec_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnb=MultinomialNB()\n",
    "model=mnb.fit(train_vec_2,ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49.8"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(train_vec_2,ratings)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_tf=model.predict(test_vec_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_tf=np.array(predictions_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41.0\n"
     ]
    }
   ],
   "source": [
    "num=np.sum(predictions_tf==output_ratings)\n",
    "accuracy=num/len(predictions_tf)\n",
    "print(accuracy*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#UNFORTUNATELY THIS IS NOT WORKING  AS GOOD AS COUNTVECTORIZER, LET US TRY WITH A DIFFERENT NAIVE BAYES MODEL , LETS GO WITH BERNOULLI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "bnb=BernoulliNB(binarize=0.0)\n",
    "model=bnb.fit(train_vec,ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52.800000000000004"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(train_vec,ratings)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41.0\n"
     ]
    }
   ],
   "source": [
    "predictions_bnb=model.predict(test_vec)\n",
    "predictions_bnb=np.array(predictions_bnb)\n",
    "num=np.sum(predictions_bnb==output_ratings)\n",
    "accuracy=num/len(predictions_bnb)\n",
    "print(accuracy*100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
